# ğŸ“Š Analyse de DonnÃ©es avec Apache Spark

## ğŸ“Œ Description
Ce projet utilise **Apache Spark** et **PySpark** pour analyser de grandes quantitÃ©s de donnÃ©es financiÃ¨res. Il inclut le traitement, l'analyse et la prÃ©diction des prix de clÃ´ture des actions de plusieurs entreprises (Apple, Tesla, Google et Microsoft) Ã  l'aide de modÃ¨les de rÃ©gression linÃ©aire. Une interface interactive a Ã©tÃ© dÃ©veloppÃ©e avec **Dash** pour visualiser les tendances et les prÃ©dictions.

## ğŸš€ Technologies UtilisÃ©es
- **Apache Spark / PySpark** : Traitement et analyse des donnÃ©es
- **Python** : Langage principal du projet
- **Dash & Plotly** : Visualisation interactive des rÃ©sultats
- **Pandas** : Manipulation des donnÃ©es
- **SQL / Parquet / CSV** : Formats de stockage des donnÃ©es
- **Machine Learning** : ModÃ¨le de rÃ©gression linÃ©aire

## ğŸ“‚ Structure du Projet

```
.
â”œâ”€â”€ README.md  # Documentation du projet
â”œâ”€â”€ data        # DonnÃ©es brutes et nettoyÃ©es
â”‚   â”œâ”€â”€ financial_data.csv
â”‚   â”œâ”€â”€ financial_data.parquet
â”‚   â””â”€â”€ financial_data_cleaned.csv
â”œâ”€â”€ models      # ModÃ¨les de Machine Learning prÃ©-entraÃ®nÃ©s
â”‚   â”œâ”€â”€ stock_price_model_AAPL
â”‚   â”œâ”€â”€ stock_price_model_TSLA
â”‚   â”œâ”€â”€ stock_price_model_GOOGL
â”‚   â”œâ”€â”€ stock_price_model_MSFT
â”‚   â””â”€â”€ stock_price_model
â”œâ”€â”€ results     # RÃ©sultats et prÃ©dictions
â”œâ”€â”€ scripts     # Scripts de traitement et d'analyse
â”‚   â”œâ”€â”€ data_collection.py   # RÃ©cupÃ©ration des donnÃ©es
â”‚   â”œâ”€â”€ data_processing.py   # Nettoyage et prÃ©paration des donnÃ©es
â”‚   â”œâ”€â”€ data_analysis.py     # Analyse et visualisation
â”‚   â”œâ”€â”€ model_training.py    # EntraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ data_visualization.py # Dashboard interactif
â”‚   â”œâ”€â”€ read_local.py        # Lecture des donnÃ©es locales
â”‚   â””â”€â”€ store_local.py       # Stockage des donnÃ©es en local
â”œâ”€â”€ test_spark.py  # Test d'exÃ©cution Spark
```

## ğŸ“¥ Installation

1. **Cloner le dÃ©pÃ´t** :
   ```sh
   git clone https://github.com/ton-repo/projet_spark.git
   cd projet_spark
   ```
2. **Installer les dÃ©pendances** :
   ```sh
   pip install -r requirements.txt
   ```
3. **Configurer Apache Spark** :
   - Assurez-vous que Spark et Hadoop sont installÃ©s sur votre machine.
   - VÃ©rifiez votre environnement avec :
     ```sh
     spark-submit --version
     ```

## ğŸ“Š ExÃ©cution du Projet

### 1ï¸âƒ£ **Traitement et Nettoyage des DonnÃ©es**
```sh
python scripts/data_processing.py
```

### 2ï¸âƒ£ **EntraÃ®nement du ModÃ¨le**
```sh
python scripts/model_training.py
```

### 3ï¸âƒ£ **Lancer l'Analyse et la PrÃ©diction**
```sh
python scripts/data_analysis.py
```

### 4ï¸âƒ£ **Lancer le Dashboard Interactif**
```sh
python scripts/data_visualization.py
```
Une fois lancÃ©, ouvrez [http://127.0.0.1:8050/](http://127.0.0.1:8050/) dans votre navigateur.

## ğŸ“Œ FonctionnalitÃ©s
âœ… Extraction et nettoyage des donnÃ©es
âœ… EntraÃ®nement d'un modÃ¨le de rÃ©gression linÃ©aire
âœ… PrÃ©diction des prix de clÃ´ture des actions
âœ… Visualisation interactive avec Dash & Plotly

## ğŸ›  AmÃ©liorations Futures
- IntÃ©gration d'autres modÃ¨les de Machine Learning (Random Forest, LSTM)
- Optimisation des performances Spark avec la parallÃ©lisation
- IntÃ©gration de flux de donnÃ©es en temps rÃ©el (Kafka, Spark Streaming)

ğŸ“Œ **Auteur** : Jeff Gbanziali
ğŸ“… **Date** : Mars 2025

