import findspark
findspark.init()

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, stddev
from pyspark.sql.window import Window
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression
from pyspark.sql.utils import AnalysisException

# ğŸ“Œ Initialisation de la session Spark
spark = SparkSession.builder.appName("StockPricePrediction").getOrCreate()

# ğŸ“Œ Chargement des donnÃ©es
print("ğŸ“Œ Chargement des donnÃ©es...")
try:
    df = spark.read.parquet("../data/financial_data.parquet")
except AnalysisException as e:
    print(f"âŒ ERREUR : Impossible de charger le fichier Parquet. DÃ©tail : {e}")
    spark.stop()
    exit()

# ğŸ“Œ SÃ©lectionner les colonnes utiles
df = df.select("Date", "Close_AAPL", "Close_TSLA", "Close_GOOGL", "Close_MSFT")
df = df.withColumn("Date", col("Date").cast("date"))

# ğŸ“Œ DÃ©finir une fenÃªtre de temps pour les indicateurs financiers
windowSpec = Window.orderBy("Date").rowsBetween(-5, 0)

# ğŸ“Œ Ajouter la Moyenne Mobile (SMA) et la VolatilitÃ© (Ã‰cart-Type)
print("ğŸ“Œ Calcul des indicateurs financiers (SMA & VolatilitÃ©)...")
df = df.withColumn("SMA_AAPL", avg("Close_AAPL").over(windowSpec)) \
       .withColumn("SMA_TSLA", avg("Close_TSLA").over(windowSpec)) \
       .withColumn("SMA_GOOGL", avg("Close_GOOGL").over(windowSpec)) \
       .withColumn("SMA_MSFT", avg("Close_MSFT").over(windowSpec)) \
       .withColumn("Volatility_AAPL", stddev("Close_AAPL").over(windowSpec)) \
       .withColumn("Volatility_TSLA", stddev("Close_TSLA").over(windowSpec)) \
       .withColumn("Volatility_GOOGL", stddev("Close_GOOGL").over(windowSpec)) \
       .withColumn("Volatility_MSFT", stddev("Close_MSFT").over(windowSpec))

# ğŸ“Œ Remplacer les valeurs NULL par 0 pour Ã©viter des erreurs
df = df.fillna(0)

# ğŸ“Œ VÃ©rification des valeurs nulles avant transformation
print("ğŸ“Œ VÃ©rification des valeurs NULL :")
df.select([col(c).isNull().alias(c) for c in df.columns]).show()

# ğŸ“Œ Liste des actions Ã  entraÃ®ner
stocks = ["AAPL", "TSLA", "GOOGL", "MSFT"]

# ğŸ“Œ EntraÃ®nement et sauvegarde du modÃ¨le pour chaque action
for stock in stocks:
    print(f"\nğŸ“Œ EntraÃ®nement du modÃ¨le pour {stock}...")

    assembler = VectorAssembler(inputCols=[f"SMA_{stock}", f"Volatility_{stock}"],
                                outputCol="features",
                                handleInvalid="keep")

    df_ml = assembler.transform(df).select("features", col(f"Close_{stock}").alias("label"))

    # ğŸ“Œ VÃ©rification que les donnÃ©es sont suffisantes
    train_data, test_data = df_ml.randomSplit([0.8, 0.2], seed=42)

    if train_data.count() == 0 or test_data.count() == 0:
        print(f"âŒ ERREUR : Pas assez de donnÃ©es pour entraÃ®ner le modÃ¨le {stock}.")
        continue

    # ğŸ“Œ Initialiser le ModÃ¨le de RÃ©gression LinÃ©aire
    lr = LinearRegression(featuresCol="features", labelCol="label", maxIter=50)

    # ğŸ“Œ EntraÃ®ner le ModÃ¨le
    try:
        model = lr.fit(train_data)
        print(f"âœ… ModÃ¨le entraÃ®nÃ© avec succÃ¨s pour {stock}")

        # ğŸ“Œ Afficher les coefficients du modÃ¨le
        print(f"ğŸ“Œ Coefficients du modÃ¨le pour {stock} : {model.coefficients}")
        print(f"ğŸ“Œ Intercept du modÃ¨le pour {stock} : {model.intercept}")

        # ğŸ“Œ Ã‰valuer le modÃ¨le sur les donnÃ©es test
        predictions = model.transform(test_data)
        print(f"ğŸ“Œ PrÃ©dictions des Prix de ClÃ´ture pour {stock} :")
        predictions.select("features", "label", "prediction").show(5)

        # ğŸ“Œ Sauvegarder le ModÃ¨le avec `overwrite`
        model.write().overwrite().save(f"../models/stock_price_model_{stock}")
        print(f"ğŸ“Œ ModÃ¨le sauvegardÃ© : ../models/stock_price_model_{stock}")

    except Exception as e:
        print(f"âŒ ERREUR : Ã‰chec de l'entraÃ®nement du modÃ¨le pour {stock}. DÃ©tail : {e}")

print("\nâœ… EntraÃ®nement terminÃ© avec succÃ¨s pour toutes les actions.")

# ğŸ“Œ Fermer Spark
spark.stop()
