import findspark
findspark.init()

from pyspark.sql import SparkSession

# ğŸ“Œ CrÃ©er une session Spark
spark = SparkSession.builder.appName("StoreLocally").getOrCreate()

# ğŸ“Œ Charger les donnÃ©es nettoyÃ©es
df = spark.read.option("header", "true").option("inferSchema", "true").csv("../data/financial_data_cleaned.csv")

# ğŸ“Œ Stocker en format `Parquet` (optimisÃ© pour Spark)
parquet_path = "../data/financial_data.parquet"
df.write.mode("overwrite").parquet(parquet_path)

# ğŸ“Œ Stocker en format `CSV` (plus universel)
csv_path = "../data/financial_data.csv"
df.write.mode("overwrite").option("header", "true").csv(csv_path)

print(f"âœ… DonnÃ©es stockÃ©es localement :\n - {parquet_path} (Parquet)\n - {csv_path} (CSV)")

# ğŸ“Œ Fermer Spark
spark.stop()
